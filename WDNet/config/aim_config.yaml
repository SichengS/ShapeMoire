GENERAL:
  GPU_ID: 3
  SEED: 123
  WORKER: 8
  SAVE_PREFIX: './out_dir/aim2019'
  EXP_NAME: 'NoShape'
  TEST_BASELINE: True # If True, test the baseline model

DATA:
  DATA_TYPE: AIM # Please specify the type of the dataset (select from AIM/UHDM/FHDMi/TIP)
  TRAIN_DATASET: /home/sshen/datasets/AIM2019/Training # The training data path, e.g., ./uhdm_data/Train
  TEST_DATASET: /home/sshen/datasets/AIM2019/Testing # The test data path, e.g., ./uhdm_data/Test

MODEL:
  EN_FEATURE_NUM: 48 # The initial channel number of dense blocks of encoder
  EN_INTER_NUM: 32 # The growth rate (intermediate channel number) of dense blocks of encoder
  DE_FEATURE_NUM: 64 # The initial channel number of dense blocks of decoder
  DE_INTER_NUM: 32 # The growth rate (intermediate channel number) of dense blocks of decoder
  SAM_NUMBER: 1 # The number of SAM for each encoder or decoder level; set 1 for our ESDNet, and 2 for ESDNet-L

TRAIN:
  BATCH_SIZE: 2
  LOADER: crop # The loading way for training data, e.g., crop, resize, default; see ./dataset/load_data.py
  CROP_SIZE: 512 # Set the crop size if LOADER==crop
  RESIZE_SIZE: 384 # Set the resizing size if LOADER==crop
  SAVE_ITER: 500 # Save training images/results at each SAVE_ITER*n iter
  LOAD_EPOCH: False # If specify it, loading the corresponding model for resuming training
  LAM: 1 # The loss weight for L1 loss
  LAM_P: 1 # The loss weight for perceptual loss

TEST:
  TEST_EPOCH: 150 # Input 'auto' for loading the latest model
  SAVE_IMG: jpg # The file type (e.g., jpg, png) for saving the output image; set False to avoid saving
  LOAD_PATH: /home/sshen/WDNet/saved_models/AIM/ShapeMoire/net_checkpoints/best_epoch56_44.5422.pth # If specify a load path for a checkpoint, TEST_EPOCH will be deprecated
  EVALUATION_METRIC: True # If True, calculate metrics
  EVALUATION_TIME: False # If True, calculate processing time per image; EVALUATION_METRIC will be deprecated for accurate statistics
  EVALUATION_COST: False #If True, calculate MACs and Parameters number

SOLVER:
  EPOCHS: 60 # The total training epochs
  T_0: 50 # The total epochs for the first learning cycle (learning rate warms up then)
  T_MULT: 1 # The learning cycle would be (T_0, T_0*T_MULT, T_0*T_MULT^2, T_0*T_MULT^3, ...)
  ETA_MIN: 0.000001 # Initial learning rate in each learning cycle
  BASE_LR: 0.0002 # Learning rate in the end of each learning cycle

WDNet: 
  b1: 0.5 #adam: decay of first order momentum of gradient
  b2: 0.999 #adam: decay of first order momentum of gradient
  decay_epoch: 40 #epoch from which to start lr decay
  n_cpu: 8 #number of cpu threads to use during batch generation
  img_height: 256 #size of image height
  img_width: 256 #size of image width
  channels: 3 #number of image channels
  sample_interval: 500 #interval between sampling of images from generators
  checkpoint_interval: 1 #interval between model checkpoints
  